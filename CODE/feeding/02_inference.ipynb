{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entire-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import samplers\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from read_metadata import read_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinate-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brutal-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, glob_string):\n",
    "        self.image_files = sorted(glob.glob(glob_string))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files) // 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_raw = cv2.imread(self.image_files[idx * 2])\n",
    "        height, width = image_raw.shape[:2]\n",
    "        image = torch.as_tensor(image_raw.astype(\"float32\").transpose(2, 0, 1)).contiguous()\n",
    "        image_dict0 = {\"image\": image, \"height\": height, \"width\": width, \"file_name\": self.image_files[idx * 2]}\n",
    "        \n",
    "        image_raw = cv2.imread(self.image_files[idx * 2 + 1])\n",
    "        height, width = image_raw.shape[:2]\n",
    "        image = torch.as_tensor(image_raw.astype(\"float32\").transpose(2, 0, 1)).contiguous()\n",
    "        image_dict1 = {\"image\": image, \"height\": height, \"width\": width, \"file_name\": self.image_files[idx * 2 + 1]}\n",
    "        return [image_dict0, image_dict1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "allied-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import subprocess as sp\n",
    "\n",
    "def get_gpu_memory():\n",
    "  _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "  memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "  memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "  print(memory_free_values)\n",
    "  return memory_free_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "willing-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(im):\n",
    "    cv2.imshow('file', im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r vid_name\n",
    "metadata = read_metadata(vid_name)\n",
    "os.chdir(metadata.folder_main + 'data/')\n",
    "original_name = metadata.videoname + '.mp4'\n",
    "converted_name = metadata.videoname + '_n.mp4'\n",
    "conv_vid = 'ffmpeg -i ' + original_name + ' -vcodec copy -an ' + converted_name\n",
    "os.system(conv_vid)\n",
    "os.chdir(metadata.folder_code)\n",
    "\n",
    "#conv_vid = 'ffmpeg -i ' + original_name + ' -vf scale=1920:1080 -vcodec copy -an '+ converted_name\n",
    "\n",
    "#ffmpeg -i GH032186.mp4 -vf scale=1920:1080 GH032186_r1.mp4 \n",
    "#ffmpeg -i GH032186_r1.mp4 -vcodec copy -an GH032186_r1.mp4\n",
    "\n",
    "\n",
    "\n",
    "os.rename(metadata.folder_main + 'data/' + converted_name, metadata.folder_main + 'tmp/' + converted_name)\n",
    "videopath = metadata.folder_main + 'tmp/' + converted_name\n",
    "if not os.path.exists(metadata.folder_output):\n",
    "    os.makedirs(metadata.folder_output)\n",
    "#videopath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fluid-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\n",
    "    metadata.folder_detectron + 'configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml')\n",
    "\n",
    "cfg.MODEL.WEIGHTS = (metadata.baboon_weights)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 50\n",
    "\n",
    "cfg.SOLVER.BASE_LR = 0.005   # 0.00025 pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 4000    # 300 iterations seems good enough for this toy dataset; \n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set a custom testing threshold\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from decord import VideoReader\n",
    "from decord import cpu, gpu\n",
    "\n",
    "def extract_frames(video_path, frames_dir, overwrite=False, start=-1, end=-1, every=1):\n",
    "    \"\"\"\n",
    "    Extract frames from a video using decord's VideoReader\n",
    "    :param video_path: path of the video\n",
    "    :param frames_dir: the directory to save the frames\n",
    "    :param overwrite: to overwrite frames that already exist?\n",
    "    :param start: start frame\n",
    "    :param end: end frame\n",
    "    :param every: frame spacing\n",
    "    :return: count of images saved\n",
    "    \"\"\"\n",
    "\n",
    "    #video_path = os.path.normpath(video_path)  # make the paths OS (Windows) compatible\n",
    "    #frames_dir = os.path.normpath(frames_dir)  # make the paths OS (Windows) compatible\n",
    "\n",
    "    video_dir, video_filename = os.path.split(video_path)  # get the video path and filename from the path\n",
    "\n",
    "    assert os.path.exists(video_path)  # assert the video file exists\n",
    "\n",
    "    # load the VideoReader\n",
    "    vr = VideoReader(video_path, ctx=cpu(0))  # can set to cpu or gpu .. ctx=gpu(0)\n",
    "                     \n",
    "    if start < 0:  # if start isn't specified lets assume 0\n",
    "        start = 0\n",
    "    if end < 0:  # if end isn't specified assume the end of the video\n",
    "        end = len(vr)\n",
    "\n",
    "    frames_list = list(range(start, end, every))\n",
    "    saved_count = 0\n",
    "\n",
    "    if every > 50 and len(frames_list) < 1000:  # this is faster for every > 25 frames and can fit in memory\n",
    "        frames = vr.get_batch(frames_list).asnumpy()\n",
    "\n",
    "        for index, frame in zip(frames_list, frames):  # lets loop through the frames until the end\n",
    "            save_path = os.path.join(frames_dir, \"{:010d}.jpg\".format(index))  # create the save path\n",
    "            if not os.path.exists(save_path) or overwrite:  # if it doesn't exist or we want to overwrite anyways\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))  # save the extracted image\n",
    "                saved_count += 1  # increment our counter by one\n",
    "\n",
    "    else:  # this is faster for every <25 and consumes small memory\n",
    "        for index in range(start, end):  # lets loop through the frames until the end\n",
    "            frame = vr[index]  # read an image from the capture\n",
    "            \n",
    "            if index % every == 0:  # if this is a frame we want to write out based on the 'every' argument\n",
    "                save_path = os.path.join(frames_dir, \"{:010d}.jpg\".format(index))  # create the save path\n",
    "                if not os.path.exists(save_path) or overwrite:  # if it doesn't exist or we want to overwrite anyways\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame.asnumpy(), cv2.COLOR_RGB2BGR))  # save the extracted image\n",
    "                    saved_count += 1  # increment our counter by one\n",
    "\n",
    "    return saved_count  # and return the count of the images we saved\n",
    "\n",
    "\n",
    "def video_to_frames(video_path, frames_dir, overwrite=False, every=1):\n",
    "    \"\"\"\n",
    "    Extracts the frames from a video\n",
    "    :param video_path: path to the video\n",
    "    :param frames_dir: directory to save the frames\n",
    "    :param overwrite: overwrite frames if they exist?\n",
    "    :param every: extract every this many frames\n",
    "    :return: path to the directory where the frames were saved, or None if fails\n",
    "    \"\"\"\n",
    "\n",
    "    #   trim 20 seconds starting on 10 second\n",
    "    #   ffmpeg -ss 00:00:10 -i GH044129_n.mp4 -c copy -t 00:00:20 GH044129_n1.mp4\n",
    "\n",
    "\n",
    "    #video_path = os.path.normpath(video_path)  # make the paths OS (Windows) compatible\n",
    "    #frames_dir = os.path.normpath(frames_dir)  # make the paths OS (Windows) compatible\n",
    "\n",
    "    video_dir, video_filename = os.path.split(video_path)  # get the video path and filename from the path\n",
    "    video_filename = video_filename\n",
    "\n",
    "    # make directory to save frames, its a sub dir in the frames_dir with the video name\n",
    "    os.makedirs(os.path.join(frames_dir), exist_ok=True)\n",
    "    \n",
    "    print(\"Extracting frames from {}\".format(video_filename))\n",
    "    \n",
    "    extract_frames(video_path, frames_dir, every=every)  # let's now extract the frames\n",
    "\n",
    "    return os.path.join(frames_dir)  # when done return the directory containing the frames\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    # test it\n",
    "    # video_to_frames(video_path='test.mp4', frames_dir='test_frames', overwrite=False, every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting frames from GH944129_n.mp4\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/baboonfield/Documents/CV/feeding/im/'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#t = time.time()\n",
    "video_to_frames(video_path=videopath , frames_dir=metadata.folder_images, overwrite=True, every=1)\n",
    "#print(time.time() - t)\n",
    "os.remove(videopath)"
   ]
  },
  {
   "source": [
    "t = time.time()\n",
    "#get jpg from video\n",
    "vid_cap = cv2.VideoCapture(videopath)\n",
    "num_frames = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "count = 1\n",
    "while count<num_frames+1:\n",
    "    vid_cap.set(1, count)\n",
    "    success, image = vid_cap.read()   \n",
    "    if success:\n",
    "        cv2.imwrite(metadata.folder_main + \"im/frame%d.jpg\" % count, image) # save frame as JPEG file      \n",
    "    else:\n",
    "        print('Read a new frame %d: ' % count, success)\n",
    "    count += 10\n",
    "\n",
    "print(time.time() - t)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sexual-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PredictDataset(os.path.join(metadata.folder_images , \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "automated-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)\n",
    "_ = model.eval()\n",
    "\n",
    "checkpointer = DetectionCheckpointer(model)\n",
    "_ = checkpointer.load(cfg.MODEL.WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "proper-breach",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[6652]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[6652]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "cuda0 = torch.device('cuda:0')\n",
    "#get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cooperative-stick",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "extracting detections 200.0631127357483\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "max_batches = 15000\n",
    "\n",
    "t = time.time()\n",
    "with torch.no_grad():\n",
    "    for batch_num, image_batch in enumerate(data_loader):\n",
    "        if batch_num >= max_batches:\n",
    "            break\n",
    "            \n",
    "        ###if batch_num % 250 == 0:\n",
    "            ###print('{} images processed'.format(batch_num * 2))\n",
    "        for i in range(len(image_batch)):\n",
    "            image_batch[i]['image'] = np.squeeze(image_batch[i]['image'])\n",
    "            image_batch[i]['image'] = image_batch[i]['image'].to(cuda0)\n",
    "            image_batch[i]['width'] = image_batch[i]['width'].to(cuda0).item()\n",
    "            image_batch[i]['height'] = image_batch[i]['height'].to(cuda0).item()\n",
    "            #print(image_batch[i]['width'])\n",
    "        predictions = model(image_batch)\n",
    "        for preds, im_dict in zip(predictions, image_batch):\n",
    "            name = os.path.splitext(os.path.basename(im_dict['file_name'][0]))[0]\n",
    "            file = os.path.join(metadata.folder_output, '{}-predictions.pkl'.format(name))\n",
    "            preds_instance = preds[\"instances\"].to(\"cpu\")\n",
    "            with open(file, 'wb') as out:\n",
    "                pickle.dump(preds_instance, out)\n",
    "                out.close()\n",
    "            \n",
    "print('extracting detections ' + str(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/baboonfield/Documents/CV/feeding/output/GH944129/GH944129_detections.npy'"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "metadata.folder_output + vid_name + '_detections.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(os.path.join(metadata.folder_output, '*-predictions.pkl')))\n",
    "\n",
    "all_detections = []\n",
    "raw_instances = []\n",
    "\n",
    "for file in files[:]:\n",
    "    with open(file, 'rb') as readfile:\n",
    "        detections=pickle.load(readfile)\n",
    "    detection_dict = detections.get_fields()\n",
    "    detection_dict['pred_boxes'] = detection_dict['pred_boxes'].tensor.numpy()\n",
    "    detection_dict['scores'] = detection_dict['scores'].numpy()\n",
    "    detection_dict['pred_classes'] = detection_dict['pred_classes'].numpy()\n",
    "    detection_dict['image_name'] = os.path.basename(file).split('-')[0]\n",
    "    all_detections.append(detection_dict)\n",
    "    raw_instances.append(detections)\n",
    "\n",
    "np_detections_file = metadata.folder_output + \"detections_\" + vid_name + \".npy\"\n",
    "np.save(np_detections_file, all_detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "working-institution",
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1728x2016 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = [np_detections_file]\n",
    "###print( files )\n",
    "fig = plt.figure( figsize = ( 24, 28 ) )  \n",
    "for file in files[0:1]:\n",
    "    detections = np.load(file, allow_pickle=True)\n",
    "    for image_ind in random.sample(range(0, len(detections)), 5): \n",
    "\n",
    "        ###print(detections[image_ind]['scores'].shape)\n",
    "        ###print(detections[image_ind]['image_name'])\n",
    "    \n",
    "        img = plt.imread(metadata.folder_images + detections[image_ind]['image_name'] + '.jpg')   \n",
    "        plt.imshow( img )\n",
    "        \n",
    "        # Get the current reference\n",
    "        ax = plt.gca()\n",
    "        for item in range(0,len(detections[image_ind]['pred_boxes'])):\n",
    "            \n",
    "            x1 = detections[image_ind]['pred_boxes'][item][0]\n",
    "            x2 =  detections[image_ind]['pred_boxes'][item][2]\n",
    "            y1 =  detections[image_ind]['pred_boxes'][item][1]\n",
    "            y2 =  detections[image_ind]['pred_boxes'][item][3]\n",
    "            scoretext =  str(\"{0:.2g}\".format(detections[image_ind]['scores'][item]))\n",
    "            \n",
    "            # Create a Rectangle patch\n",
    "            wid = x2 - x1       \n",
    "            hei = y2 - y1\n",
    "            rect = plt.Rectangle((x1, y1), wid, hei, linewidth=1, edgecolor='c', facecolor='none')\n",
    "            ax.add_patch( rect )\n",
    "            ax.annotate(scoretext,(x1, y1),size = 20)\n",
    "            #ax.add_patch( textplt )\n",
    "\n",
    "            # Add the patch to the Axes\n",
    "            plt.scatter(x= [ x1 , x2 ], y= [ y1, y2 ], c='r', s=10)\n",
    "        plt.savefig(metadata.folder_main + 'annotated/' + vid_name + '_' + detections[image_ind]['image_name'] + '.jpg', bbox_inches = 'tight' )\n",
    "        plt.clf()\n"
   ]
  },
  {
   "source": [
    "files_in_directory = os.listdir(metadata.folder_output)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\".pkl\")]\n",
    "for file in filtered_files:\n",
    "\tpath_to_file = os.path.join(metadata.folder_output, file)\n",
    "\tos.remove(path_to_file)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}