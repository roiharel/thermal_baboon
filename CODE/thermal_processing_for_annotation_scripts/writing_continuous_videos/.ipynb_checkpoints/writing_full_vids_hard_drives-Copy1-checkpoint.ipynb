{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnv\n",
    "import fnv.reduce\n",
    "import fnv.file\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import time\n",
    "import pandas as pd\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import h5py\n",
    "import gc\n",
    "import shlex\n",
    "import pipes\n",
    "from subprocess import check_call\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6dd351122000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-d9a00a9e25e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\meerkat\\detectron2-windows\\detectron2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meerkat\\detectron2-windows\\detectron2\\utils\\env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mTORCH_VERSION\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \"\"\"\n\u001b[0;32m     17\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m2\u001b[0m \u001b[0mints\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mUseful\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-dbcdbd41619c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meerkat\\detectron2-windows\\detectron2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meerkat\\detectron2-windows\\detectron2\\utils\\env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mTORCH_VERSION\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \"\"\"\n\u001b[0;32m     17\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m2\u001b[0m \u001b[0mints\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mUseful\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import samplers\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-cba48d975158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPredictDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class PredictDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, glob_string):\n",
    "        self.image_files = sorted(glob.glob(glob_string))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files) // 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_raw = cv2.imread(self.image_files[idx * 2])\n",
    "        height, width = image_raw.shape[:2]\n",
    "        image = torch.as_tensor(image_raw.astype(\"float32\").transpose(2, 0, 1)).contiguous()\n",
    "        image_dict0 = {\"image\": image, \"height\": height, \"width\": width, \"file_name\": self.image_files[idx * 2]}\n",
    "        \n",
    "        image_raw = cv2.imread(self.image_files[idx * 2 + 1])\n",
    "        height, width = image_raw.shape[:2]\n",
    "        image = torch.as_tensor(image_raw.astype(\"float32\").transpose(2, 0, 1)).contiguous()\n",
    "        image_dict1 = {\"image\": image, \"height\": height, \"width\": width, \"file_name\": self.image_files[idx * 2 + 1]}\n",
    "        return [image_dict0, image_dict1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(im):\n",
    "    cv2.imshow('file', im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing all frames from a given thermal recording, separated into minute bins. Timestamps unrounded\n",
    "\n",
    "zoom = 5\n",
    "\n",
    "start_frame = 0\n",
    "\n",
    "vid_length = 1*60*60\n",
    "\n",
    "drive = 'E:/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-08-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Users/meerkat/Documents/thermal_baboon/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to = root + 'DATA/images_to_process/' + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-aef2c3a5bb2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#root = 'Y:/cloftus/analysis/thermal_baboon_project/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'DATA/short_temp/all_coco_annotations'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meerkat\\detectron2-windows\\detectron2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meerkat\\detectron2-windows\\detectron2\\utils\\env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mTORCH_VERSION\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \"\"\"\n\u001b[0;32m     17\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m2\u001b[0m \u001b[0mints\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mUseful\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "## root on my local computer\n",
    "# root = 'C:/Users/cloftus/Documents/thermal_baboons/annotations/'\n",
    "\n",
    "## root on my HiWi computer\n",
    "root = 'C:/Users/meerkat/Documents/thermal_baboon/'\n",
    "\n",
    "## root on the server\n",
    "#root = 'Y:/cloftus/analysis/thermal_baboon_project/'\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "output_folder = root + 'DATA/short_temp/all_coco_annotations'\n",
    "coco_annotation_file = os.path.join(output_folder, 'baboon_coco_annotations.json')\n",
    "output_image_folder = os.path.join(output_folder, 'images')\n",
    "\n",
    "register_coco_instances(\"train\",  {}, coco_annotation_file, output_image_folder ) \n",
    "\n",
    "train_metadata = MetadataCatalog.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faster_rcnn_R_101_C4_3x.yaml',\n",
       " 'faster_rcnn_R_101_DC5_3x.yaml',\n",
       " 'faster_rcnn_R_101_FPN_3x.yaml',\n",
       " 'faster_rcnn_R_50_C4_1x.yaml',\n",
       " 'faster_rcnn_R_50_C4_3x.yaml',\n",
       " 'faster_rcnn_R_50_DC5_1x.yaml',\n",
       " 'faster_rcnn_R_50_DC5_3x.yaml',\n",
       " 'faster_rcnn_R_50_FPN_1x.yaml',\n",
       " 'faster_rcnn_R_50_FPN_3x.yaml',\n",
       " 'faster_rcnn_X_101_32x8d_FPN_3x.yaml',\n",
       " 'fast_rcnn_R_50_FPN_1x.yaml',\n",
       " 'output',\n",
       " 'retinanet_R_101_FPN_3x.yaml',\n",
       " 'retinanet_R_50_FPN_1x.yaml',\n",
       " 'retinanet_R_50_FPN_3x.yaml',\n",
       " 'rpn_R_50_C4_1x.yaml',\n",
       " 'rpn_R_50_FPN_1x.yaml']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##base root on my local computer\n",
    "#base_root = 'C:/Users/cloftus/'\n",
    "\n",
    "##base root on the HiWi computer\n",
    "base_root = 'C:/Users/meerkat/'\n",
    "\n",
    "os.chdir( base_root + 'detectron2-windows/configs/COCO-Detection/' )\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a7d640d22793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m cfg.merge_from_file(\n\u001b[0;32m      3\u001b[0m     \u001b[0mbase_root\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'detectron2-windows/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_cfg' is not defined"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\n",
    "    base_root + 'detectron2-windows/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml'\n",
    ")\n",
    "\n",
    "baboon_weights = root + \"RESULTS/detectron_output/output/full-aug_maxiter-2000_lr-0.019_detectPerIm-200_minsize-0_batchsize-8/model_final.pth\"\n",
    "\n",
    "\n",
    "\n",
    "cfg.MODEL.WEIGHTS = (baboon_weights)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (100)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir( drive + date.replace( '-', '') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal_file = glob.glob('*.seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20190814_17_00_00-226_14_00_04_981.seq']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thermal_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = fnv.file.ImagerFile( thermal_file[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.get_frame(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fnv.file.ImagerFile at 0x20e26dc2f30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_frame\n",
      "got_frame\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n",
      "hooray\n",
      "made it\n",
      "got_frame\n",
      "ahoy there\n",
      "here??\n",
      "did you make it here?\n",
      "what about here?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "im.get_frame(0)\n",
    "\n",
    "print( 'got_frame')\n",
    "\n",
    "day1 = int(im.frame_info[0]['value'][:3])\n",
    "\n",
    "start = date + ' ' + im.frame_info[0]['value'][4:]\n",
    "\n",
    "start_dt = dt.datetime.strptime(start, '%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "## save the first timestamp. We will add one to the date from this timestamp for all times that occur after midnight\n",
    "og_start_dt = start_dt\n",
    "\n",
    "## make the directory where we will write the images to\n",
    "os.makedirs ( write_to + '/', exist_ok = True)\n",
    "\n",
    "os.chdir( write_to + '/')\n",
    "\n",
    "## set up the plot areas\n",
    "final = np.array(im.final, copy=False).reshape((im.height, im.width))\n",
    "    \n",
    "width = final.shape[1] / (100 / zoom)\n",
    "    \n",
    "height = final.shape[0] / (100 / zoom)\n",
    "\n",
    "fig = plt.figure( figsize = ( width, height ) )  \n",
    "\n",
    "print( 'got_frame')\n",
    "\n",
    "\n",
    "## I am not exactly sure what this if else statement does, but it has something to do with starting on a new video that is not starting at the beginning timestamp in case we are not starting at the first frame\n",
    "if start_frame > 0:\n",
    "    \n",
    "    jumper = 0\n",
    "    \n",
    "else:\n",
    "    \n",
    "    jumper = 1\n",
    "    \n",
    "for i in range(start_frame, im.num_frames ): ## for each frame\n",
    "    \n",
    "    ## this will stop the code if there is an error with reading in the frame (which happens when reading from the server)\n",
    "    if im.get_frame( i ) == False:\n",
    "        blaasdfadff\n",
    "        \n",
    "    print( 'made it' )\n",
    "    ## read in the frame\n",
    "    im.get_frame(i)\n",
    "\n",
    "    print( 'got_frame')\n",
    "\n",
    "    ## pull the day of the frame\n",
    "    day2 = int(im.frame_info[0]['value'][:3])\n",
    "\n",
    "    ## determine if this is the same day as when the video started (i.e. is it past midnight?)\n",
    "    day_diff = day2 - day1\n",
    "\n",
    "    ## save the timestamp of the frame\n",
    "    timestamp = f'{og_start_dt.year:04}-' + f'{og_start_dt.month:02}-' + f'{(og_start_dt.day+day_diff):02} ' + im.frame_info[0]['value'][4:]\n",
    "\n",
    "    ## turn the character string timestamp into an actual datetime timestamp\n",
    "    timestamp = dt.datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    ## if it has been an hour since the start of the first frame of this video, pause the frame printing, and make a video from the frames of the previous hour\n",
    "    if timestamp > ( start_dt + dt.timedelta( seconds = vid_length ) ):\n",
    "        \n",
    "        print( 'heyo' )\n",
    "        ## if we started at the beginning of the video, make a video of the frames in the past hour. If we didn't start at the beginning of the video, set the start_dt to the current timestamp, and we will start the new video at this frame (if we are on the first frame -- not the first frame of the video, but the first frame that we input above)\n",
    "        if not jumper == 0:\n",
    "           \n",
    "            ## prepare the name of the video. This is the timestamp of the first frame of the video\n",
    "            str_name = start_dt.strftime(\"%Y%m%d_%H%M%S%f\")\n",
    "\n",
    "            \n",
    "            ### and now doing prediction within the frames in the past hour\n",
    "            # FOLDER THAT HAS THE IMAGES YOU WANT TO PROCESS\n",
    "            images_folder = write_to\n",
    "\n",
    "            dataset = PredictDataset(os.path.join(images_folder, \"*.png\"))\n",
    "\n",
    "            save_root = root + 'RESULTS/processed_images/' + date\n",
    "            \n",
    "            os.makedirs(save_root, exist_ok = True)\n",
    "\n",
    "            data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers = 0 )\n",
    "            \n",
    "            cuda0 = torch.device('cuda:0')\n",
    "            \n",
    "            \n",
    "            max_batches = 10000\n",
    "\n",
    "            t = time.time()\n",
    "            with torch.no_grad():\n",
    "                for batch_num, image_batch in enumerate(data_loader):\n",
    "                    if batch_num >= max_batches:\n",
    "                        break\n",
    "\n",
    "                    if batch_num % 250 == 0:\n",
    "                        print('{} images processed'.format(batch_num * 2))\n",
    "                    for i in range(len(image_batch)):\n",
    "                        image_batch[i]['image'] = np.squeeze(image_batch[i]['image'])\n",
    "\n",
    "                        image_batch[i]['image'] = image_batch[i]['image'].to(cuda0)\n",
    "                        image_batch[i]['width'] = image_batch[i]['width'].to(cuda0).item()\n",
    "                        image_batch[i]['height'] = image_batch[i]['height'].to(cuda0).item()\n",
    "                        #print(image_batch['image'].shape)\n",
    "                        #print(image_batch)\n",
    "                    predictions = model(image_batch)\n",
    "                    for preds, im_dict in zip(predictions, image_batch):\n",
    "                        name = os.path.splitext(os.path.basename(im_dict['file_name'][0]))[0]\n",
    "                        file = os.path.join(save_root, '{}-predictions.pkl'.format(name))\n",
    "                        preds_instance = preds[\"instances\"].to(\"cpu\")\n",
    "                        with open(file, 'wb') as out:\n",
    "                            pickle.dump(preds_instance, out)\n",
    "                            out.close()\n",
    "\n",
    "            print(time.time() - t, flush = True )\n",
    "            np_detections_file = os.path.join(save_root, '{}_detections.npy'.format(name))\n",
    "\n",
    "            files = sorted(glob.glob(os.path.join(save_root, '*-predictions.pkl')))\n",
    "\n",
    "            all_detections = []\n",
    "            raw_instances = []\n",
    "\n",
    "            for file in files[:]:\n",
    "                with open(file, 'rb') as readfile:\n",
    "                    detections=pickle.load(readfile)\n",
    "                    #print( detections )\n",
    "                detection_dict = detections.get_fields()\n",
    "                detection_dict['pred_boxes'] = detection_dict['pred_boxes'].tensor.numpy()\n",
    "                detection_dict['scores'] = detection_dict['scores'].numpy()\n",
    "                detection_dict['pred_classes'] = detection_dict['pred_classes'].numpy()\n",
    "                detection_dict['image_name'] = os.path.basename(file).split('-')[0]\n",
    "                all_detections.append(detection_dict)\n",
    "                raw_instances.append(detections)\n",
    "\n",
    "            np_detections_file = os.path.join(save_root, '{}_detections.npy'.format(name) )\n",
    "            np.save(np_detections_file, all_detections)\n",
    "            \n",
    "            os.chdir( save_root )\n",
    "            \n",
    "            counter = 0\n",
    "\n",
    "            for detection in all_detections:\n",
    "\n",
    "                print(detection['scores'].shape)\n",
    "                print(detection['image_name'])\n",
    "\n",
    "                img = plt.imread( root + 'DATA/images_to_process/' + detection['image_name'] + '.tiff' )\n",
    "\n",
    "                #img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB )\n",
    "                plt.imshow( img )\n",
    "\n",
    "                # Get the current reference\n",
    "                ax = plt.gca()\n",
    "\n",
    "                ax.axes.xaxis.set_visible(False)\n",
    "                ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "                for item in detection['pred_boxes']:\n",
    "\n",
    "                    x1 = item[ 0 ]\n",
    "\n",
    "                    x2 = item[ 2 ]\n",
    "\n",
    "                    y1 = item[ 1 ]\n",
    "\n",
    "                    y2 = item[ 3 ]\n",
    "\n",
    "                    wid = x2 - x1\n",
    "\n",
    "                    hei = y2 - y1\n",
    "\n",
    "                    # Create a Rectangle patch\n",
    "                    rect = patches.Rectangle( (x1, y1 ), wid, hei, linewidth=1, edgecolor='c', facecolor='none' )\n",
    "\n",
    "                    # Add the patch to the Axes\n",
    "                    ax.add_patch( rect )\n",
    "\n",
    "                plt.savefig( save_root + '/' + detection['image_name'] , bbox_inches = 'tight' )\n",
    "\n",
    "                fig.clear()\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "            asdfgafaafd\n",
    "            \n",
    "            name = image_batch[0]['file_name'][0].split('/')[-2]\n",
    "            \n",
    "            # make a text_file of all the tiffs in the folder where we have been printing the frames\n",
    "            text_file = open(str_name + '.txt', 'w')\n",
    "\n",
    "            files = sorted( os.listdir() )\n",
    "\n",
    "            for file in files:\n",
    "\n",
    "                if 'png' in file:\n",
    "\n",
    "                    n = text_file.write('file ' + \"'\" + file + \"'\" + '\\n')\n",
    "\n",
    "            text_file.close()\n",
    "\n",
    "            ## command line script for turning the frames we printed and saved into a video\n",
    "            txt_name = str_name + '.txt'\n",
    "            vid_name = str_name + '.mp4'\n",
    "\n",
    "            command = 'ffmpeg -f concat -r 60 -i ' + pipes.quote( txt_name ) + ' -c:v libx264 -crf 15 -pix_fmt yuv420p -vf pad=ceil(iw/2)*2:ceil(ih/2)*2 ' + pipes.quote(vid_name)\n",
    "            check_call(shlex.split(command))\n",
    "\n",
    "        \n",
    "        to_delete = glob.glob('*.png')\n",
    "        \n",
    "        for item in to_delete:\n",
    "            os.remove( item )\n",
    "        \n",
    "        start_dt = timestamp\n",
    "        \n",
    "        jumper = 1\n",
    "        #os.makedirs ( write_to + '/' + start_dt.strftime(\"%Y%m%d_%H%M%S%f\") )\n",
    "        \n",
    "        #os.chdir( write_to + '/' + start_dt.strftime(\"%Y%m%d_%H%M%S%f\") )\n",
    "     \n",
    "    \n",
    "    #print( 'if_statement: ' , time.time() - start__t )\n",
    "\n",
    "    #start__ = time.time()\n",
    "        \n",
    "        \n",
    "    print( 'ahoy there' )\n",
    "    final = np.array(im.final, copy=False).reshape( ( im.height, im.width ) )\n",
    "\n",
    "    final1 = final - final.mean()\n",
    "    \n",
    "    #print( 'matrix: ' , time.time() - start__ )\n",
    "\n",
    "    #start__ = time.time()\n",
    "\n",
    "    print( 'here??' )\n",
    "    sns.heatmap(final1, vmin = -np.std(final1), vmax = final1.max(), xticklabels = False, yticklabels = False, cbar = False)\n",
    "\n",
    "    print( 'did you make it here?')\n",
    "    if final1.shape[1] > 1000:\n",
    "\n",
    "        plt.xlabel(  timestamp.strftime(\"%Y-%m-%d %H:%M:%S.%f\") , fontsize = 55*zoom / 5 )\n",
    "\n",
    "    else:\n",
    "\n",
    "        plt.xlabel(  timestamp.strftime(\"%Y-%m-%d %H:%M:%S.%f\") , fontsize = 25*zoom / 5 )\n",
    "\n",
    "    \n",
    "    #print( 'plotting: ' , time.time() - start__ )\n",
    "\n",
    "    #start__ = time.time()\n",
    "\n",
    "    print( 'what about here?' )\n",
    "    plt.savefig( f'{i:06}_' + timestamp.strftime(\"%Y%m%d_%H%M%S%f\") + '.png' , bbox_inches = 'tight')\n",
    "    \n",
    "    #print( 'save_plot: ' , time.time() - start__ )\n",
    "\n",
    "    #start__ = time.time()\n",
    "    \n",
    "    print( 'hooray' )\n",
    "    \n",
    "    fig.clear()\n",
    "    \n",
    "    #plt.clf()\n",
    "    \n",
    "    #plt.cla()\n",
    "\n",
    "    #plt.close( fig )\n",
    "    #plt.close( 'all' )\n",
    "    \n",
    "    del day2, day_diff, final, final1\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    #print( 'clean_up: ' , time.time() - start__ )\n",
    "    \n",
    "    #print( 'total_iter: ' , time.time() - start__t )\n",
    "\n",
    "\n",
    "    \n",
    "    #h = hpy()\n",
    "    #print(h.heap())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_name = start_dt.strftime(\"%Y%m%d_%H%M%S%f\")\n",
    "\n",
    "# make a text_file of all the tiffs in the folder\n",
    "text_file = open(str_name + '.txt', 'w')\n",
    "\n",
    "files = sorted( os.listdir() )\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    \n",
    "    if 'png' in file:\n",
    "\n",
    "        n = text_file.write('file ' + \"'\" + file + \"'\" + '\\n')\n",
    "\n",
    "text_file.close()\n",
    "\n",
    "## command line script for turning the series of pictures produced in the script below to movies for upload\n",
    "\n",
    "txt_name = str_name + '.txt'\n",
    "vid_name = str_name + '.mp4'\n",
    "\n",
    "command = 'ffmpeg -f concat -r 60 -i ' + pipes.quote( txt_name ) + ' -c:v libx264 -crf 15 -pix_fmt yuv420p -vf pad=ceil(iw/2)*2:ceil(ih/2)*2 ' + pipes.quote(vid_name)\n",
    "check_call(shlex.split(command))\n",
    "\n",
    "\n",
    "#to_delete = glob.glob('*.png')\n",
    "\n",
    "#for item in to_delete:\n",
    "#    os.remove( item )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = glob.glob('*.png')\n",
    "\n",
    "for item in to_delete:\n",
    "    os.remove( item )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
